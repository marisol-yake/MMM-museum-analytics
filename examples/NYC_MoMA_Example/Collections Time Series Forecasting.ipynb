{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ecdaf1-531a-465c-ac72-ae5271987205",
   "metadata": {},
   "source": [
    "# NYC MoMA Artworks - Collections In-take and Space-use Forecasting\n",
    "\n",
    "## Table of Contents\n",
    "<ol>\n",
    "  <li><a href=\"#load-libraries\">Load libraries</a></li>\n",
    "  <li><a href=\"#data-process\">Data Preprocessing</a></li>\n",
    "  <li><a href=\"#ts-decomp\">Overall Time Series Decomposition</a></li>\n",
    "  <li><a href=\"#spatial\">Spatial Time Series Analysis</a></li>\n",
    "  <ol>\n",
    "    <li><a href=\"#spatial-ts\">Analysis of Space-use over Time</a></li>\n",
    "  </ol>\n",
    "  <li><a href=\"#ts-model-declare\">Time Series Model Initialization</a></li>\n",
    "  <li><a href=\"#ts-model\">Time Series Model Comparisons</a></li>\n",
    "  <ol>\n",
    "    <li><a href=\"#ts-model-tv\">Time Series Model Training & Validation</a></li>\n",
    "    <li><a href=\"#ts-model-forecast\">Time Series Forecasting Estimates</a></li>\n",
    "  </ol>\n",
    "  <li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "  <li><a href=\"#recommendations\">Recommendations</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f9c8c-fca9-449a-8c82-1602b8f16a99",
   "metadata": {},
   "source": [
    "<section id=\"load-libraries\">\n",
    "    <h2>Load Libraries</h2>\n",
    "</section>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf2001e5-1304-4131-a71a-f74889d92cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "from darts import TimeSeries\n",
    "from darts.models import NaiveDrift, NaiveMovingAverage, ExponentialSmoothing, Croston\n",
    "from darts.statistics import check_seasonality, stationarity_tests, plot_residuals_analysis\n",
    "import statsmodels.api as sm\n",
    "from sklearn import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d27bc3-f2a1-45b3-844d-cc5326a46dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Necessary Functions\n",
    "def gen_ts_features(df, date_column):\n",
    "    # Generates Time Series Features based on date_column\n",
    "    # Makes for easier analysis of operational (day-to-day) processes.\n",
    "    # df[\"date_column\"] = pd.to_datetime(df[date_column])\n",
    "    df[\"day_of_week\"] = df[date_column].dt.day_name()\n",
    "    df[\"week_of_month\"] = (df.date_column.day / 7).apply(lambda x: math.ceil(x))\n",
    "    df[\"week_of_year\"] = df[date_column].dt.isocalendar().week\n",
    "    df[\"month_of_year\"] = df[date_column].dt.month_name()\n",
    "    df[\"year\"] = df[date_column].dt.isocalendar().year\n",
    "    return df\n",
    "\n",
    "def is_stationary(series):\n",
    "    # Hypothesis Testing for Time Series data\n",
    "    # Perform two separate stationarity tests\n",
    "    result = stationarity_tests(series, p_value_threshold_adfuller=0.05, p_value_threshold_kpss=0.05)\n",
    "\n",
    "    if result:\n",
    "        print(\"The time series is stationary.\")\n",
    "    else:\n",
    "        print(\"The time series is non-stationary.\")\n",
    "    return result\n",
    "\n",
    "def has_seasonality(series):\n",
    "    result = check_seasonality(series)\n",
    "\n",
    "    if result[0]:\n",
    "        print(f\"The time series has seaonality, with a period of {result[1]}\")\n",
    "    else:\n",
    "        print(\"The time series does not have seasonality.\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb290019-60ab-42cf-a911-391c44a592da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Sample data (replace with your actual data)\n",
    "X = pd.DataFrame(np.random.randn(100, 10))  # Features\n",
    "y = np.random.randn(100)  # Target\n",
    "\n",
    "# Sort data by date column\n",
    "\n",
    "# spatial_totol_series\n",
    "# accession_counts_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a714e-6cfd-4f7d-ab2b-da6bc3742edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial Analysis\n",
    "# Plot with trend lines for each category\n",
    "sns.lmplot(x = \"obj_num\", y = \"spatial_total\", hue = \"category\", data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1315438d-6df8-4a32-b853-6dca0c969d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with trend lines for each category\n",
    "sns.lmplot(x = \"obj_num\", y = \"acc_sum\", hue = \"category\", data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d1953a-059d-4695-b2bc-7cf9e2aa050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next two steps are operative for knowing which models apply\n",
    "# to the domain our data fits into (read: intermittent demand forecasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632d7aca-2010-49a3-bf33-6af288fee324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall TS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf4d8f-0b57-4498-a7c8-9dea8ea5f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly Rolling Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c111255-49a6-48ae-b224-ca5b8b3c3405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly Rolling Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a6b58-22c4-45d2-bd8c-d8dc965919a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Statistical Tests\n",
    "is_stationary(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73402b-c683-492f-ad3f-7112fbf0046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_seasonality(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceee095-d77c-4f36-94d0-b5eb815fc274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Model Comparison Setup\n",
    "models = {\n",
    "    # Baseline Statistical Models\n",
    "    \"Naive\": NaiveDrift(),\n",
    "    \"Moving Average\": NaiveMovingAverage(),\n",
    "    \"Exponential Smoothing\": ExponentialSmoothing(),\n",
    "    \n",
    "    # Domain Specific Models - Intermittent Demand Forecasting\n",
    "    \"CROSTON Method\": Croston(version = \"classic\"),\n",
    "    \"SBA\": Croston(version = \"sba\"), # Syntetos-Boylan Approximation\n",
    "    \"TSB\": Croston(version = \"tsb\") # Teunter-Syntetos-Babai\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cde366-984c-4cde-b4d5-789be8bd11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Models for Selection\n",
    "results = {\n",
    "        \"Model\": [],\n",
    "        \"Forecast Steps\": [],\n",
    "        \"MAE\": [],\n",
    "        \"MSE\": [],\n",
    "        \"RMSE\": [],\n",
    "        \"Coverage Probability\": [],\n",
    "        \"Predictions\": [],\n",
    "}\n",
    "\n",
    "# How many periods to forecast out to\n",
    "forecast_windows = [5, 10, 15, 20, 30]\n",
    "\n",
    "# Splits data for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits = 5)\n",
    "\n",
    "# Estimating forecasts using historical data\n",
    "for model_name, model in models.items():\n",
    "    # Splits data using cross-validation\n",
    "    for train_index, test_index in tscv.split(series):\n",
    "        train, test = series[train_index], series[test_index]\n",
    "        model.fit(train)\n",
    "        \n",
    "        # Create predictions using one model \n",
    "        # over various numbers of steps out.\n",
    "        # Adjusts data-split accordingly.\n",
    "        for step_count in forecast_windows:\n",
    "            # To make sure that models forecast to their horizons honestly\n",
    "            if len(test) < step_count:\n",
    "                print(f\"Skipping model {model_name} for forecast horizon {step_count} due to insufficient amounts of test data.\")\n",
    "                continue\n",
    "            \n",
    "            predictions = model.predict(steps = step_count)\n",
    "            y_true = test[:step_count].values()\n",
    "        \n",
    "            # Metrics selected for model selection\n",
    "            mae = mean_absolute_error(y_true, predictions)\n",
    "            mse = mean_squared_error(y_true, predictions)\n",
    "            # TODO: mase\n",
    "            # TODO: r2_score\n",
    "            rmse = np.sqrt(mean_squared_error(y_true, predictions))\n",
    "            \n",
    "            # Calculate Coverage Probability (assuming a 95% prediction interval)\n",
    "            z_score = 1.96\n",
    "            lower_bound = predictions - (z_score * np.std(predictions))\n",
    "            upper_bound = predictions + (z_score * np.std(predictions))\n",
    "            coverage_probability = np.mean((y_true >= lower_bound) & (y_true <= upper_bound))\n",
    "\n",
    "            # Store all results\n",
    "            results[\"Model\"].append(model_name)\n",
    "            results[\"Forecast Steps\"].append(step_count)\n",
    "            results[\"MAE\"].append(mae)\n",
    "            results[\"MSE\"].append(mse)\n",
    "            results[\"RMSE\"].append(rmse)\n",
    "            results[\"Coverage Probability\"].append(coverage_probability)\n",
    "            results[\"Predictions\"].append(predictions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a6291-ad2d-408d-a668-20ed61c503aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance visual comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5225034-c692-4b1b-95b8-79bad1e240e3",
   "metadata": {},
   "source": [
    "Potential Future Features:\n",
    "- [ ] Hierarchical Modeling (e.g. by Department, by Credit, etc.)\n",
    "- [ ] Popular ML models (ARIMA, RandomForest, MCMC, etc.)\n",
    "- [ ] With Multi-variate Models, we can have SHAP feature importance explanation.\n",
    "- [ ] Calculating Backlog durations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b49b55-6413-474f-aeb5-3a4647de6018",
   "metadata": {},
   "source": [
    "# We're about the process!\n",
    "If streamlining means less people work, we want less of it. Data belong to the social."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
